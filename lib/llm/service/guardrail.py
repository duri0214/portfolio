from abc import ABC, abstractmethod
import os
import logging
from pathlib import Path
from typing import Callable

import chromadb
from chromadb.config import Settings
from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction
from openai import OpenAI

from lib.llm.valueobject.guardrail import (
    GuardRailSignal,
    SemanticGuardResult,
    SemanticGuardException,
)
from config.settings import BASE_DIR

logger = logging.getLogger(__name__)


class BaseGuardRailService(ABC):
    """
    ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã‚µãƒ¼ãƒ“ã‚¹ã®åŸºåº•ã‚¯ãƒ©ã‚¹
    """

    @abstractmethod
    def create_guardrail(self, *args, **kwargs) -> Callable:
        """
        OpenAI Agents SDKã§ä½¿ç”¨ã•ã‚Œã‚‹ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«é–¢æ•°ã‚’ä½œæˆã™ã‚‹
        """
        pass


class OpenAIModerationGuardService(BaseGuardRailService):
    """
    OpenAI Moderation API ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¨ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã®ä¸¡é¢ã‹ã‚‰å®‰å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã‚µãƒ¼ãƒ“ã‚¹ã€‚

    æœ¬ã‚µãƒ¼ãƒ“ã‚¹ã®ç‰¹å¾´:
    - äºŒé‡ã®ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«: ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‚ªæ„ã®ã‚ã‚‹å…¥åŠ›ã‚’é€ã£ã¦ã„ãªã„ã‹ã€ã¨ã€Œãƒ¢ãƒ‡ãƒ«ãŒä¸é©åˆ‡ãªå›ç­”ã‚’ç”Ÿæˆã—ã¦ã„ãªã„ã‹ã€ã®åŒæ–¹å‘ã‚’ç‹¬ç«‹ã—ã¦ãƒã‚§ãƒƒã‚¯ã§ãã¾ã™ã€‚
    - æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç”¨: `omni-moderation-latest` ã‚’ä½¿ç”¨ã—ã€ãƒ˜ã‚¤ãƒˆã€è‡ªå‚·è¡Œç‚ºã€æ€§çš„å†…å®¹ã€æš´åŠ›ã€ãƒãƒ©ã‚¹ãƒ¡ãƒ³ãƒˆãªã©ã®è¤‡æ•°ã®ã‚«ãƒ†ã‚´ãƒªã«ã‚ãŸã‚‹é•åã‚’è©³ç´°ã«æ¤œçŸ¥ã—ã¾ã™ã€‚
    - æŸ”è»Ÿãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°: APIã‚¨ãƒ©ãƒ¼ã‚„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã«ã€å®‰å…¨æ€§ã‚’å„ªå…ˆã—ã¦ãƒ–ãƒ­ãƒƒã‚¯ã™ã‚‹ã‹ï¼ˆå³æ ¼ãƒ¢ãƒ¼ãƒ‰ï¼‰ã€å‡¦ç†ã‚’ç¶šè¡Œã•ã›ã‚‹ã‹ã‚’è¨­å®šå¯èƒ½ã§ã™ã€‚

    æ³¨æ„ç‚¹ã¨ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•:
    - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨é…å»¶: å„ãƒã‚§ãƒƒã‚¯ï¼ˆå…¥åŠ›ãƒ»å‡ºåŠ›ï¼‰ã«ãŠã„ã¦ OpenAI ã®å¤–éƒ¨ API ã‚’å‘¼ã³å‡ºã™ãŸã‚ã€`SemanticGuardService` ã®ã‚ˆã†ãªãƒ­ãƒ¼ã‚«ãƒ«/ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ™ãƒ¼ã‚¹ã®åˆ¤å®šã¨æ¯”è¼ƒã—ã¦ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é…å»¶ãŒç™ºç”Ÿã—ã¾ã™ã€‚ç‰¹ã«ã€Œå…¥å‡ºåŠ›ã®ä¸¡é¢ã€ã§ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã†å ´åˆã¯ã€åˆè¨ˆ2å›ã®è¿½åŠ  API ã‚³ãƒ¼ãƒ«ãŒç™ºç”Ÿã—ã€å…¨ä½“ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
    - å¤–éƒ¨ä¾å­˜æ€§: OpenAI API ã®ç¨¼åƒçŠ¶æ³ã«ä¾å­˜ã—ã¾ã™ã€‚

    å‡¦ç†ã®æ¦‚è¦:
    1. ãƒ†ã‚­ã‚¹ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ï¼‰ã‚’ OpenAI Moderation API ã«é€ä¿¡ã—ã¾ã™ã€‚
    2. API ã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«åŸºã¥ãã€ãƒãƒªã‚·ãƒ¼é•åï¼ˆflaggedï¼‰ãŒã‚ã‚‹ã‹åˆ¤å®šã—ã¾ã™ã€‚
    3. é•åãŒã‚ã‚‹å ´åˆã¯ã€è©²å½“ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’ç‰¹å®šã—ã€ã‚µãƒ¼ãƒ“ã‚¹å›ºæœ‰ã®æ‹’å¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¼´ã† RED ä¿¡å·ã‚’è¿”ã—ã¾ã™ã€‚
    4. é•åãŒãªã„å ´åˆã¯ã€æ­£å¸¸ã‚’ç¤ºã™ GREEN ä¿¡å·ã‚’è¿”ã—ã¾ã™ã€‚

    ä¸»ãªç”¨é€”:
    - å…¥åŠ›ãƒã‚§ãƒƒã‚¯: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã®è©¦ã¿ã‚„ã€å…¬åºè‰¯ä¿—ã«åã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®é®æ–­ã€‚
    - å‡ºåŠ›ãƒã‚§ãƒƒã‚¯: AIãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæœŸã›ã¬ä¸é©åˆ‡ãªç™ºè¨€ã‚„ã€å¹»è¦šï¼ˆãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã«èµ·å› ã™ã‚‹æœ‰å®³æƒ…å ±ã®æä¾›é˜²æ­¢ã€‚
    """

    def __init__(self):
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    def _check_moderation(
        self,
        text: str,
        entity_name: str,
        blocked_message: str,
        strict_mode: bool = False,
    ) -> SemanticGuardResult:
        """
        OpenAI Moderation API ã‚’ä½¿ç”¨ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯ã®å®Ÿè£…ã€‚

        å‡¦ç†ã®é †ç•ª:
        1. OpenAI API ã‚’å‘¼ã³å‡ºã—ã€ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¤å®šã‚’å–å¾—ã—ã¾ã™ã€‚
        2. `flagged` ãŒ true ã®å ´åˆ:
           - é•åã‚«ãƒ†ã‚´ãƒªã‚’æŠ½å‡ºã—ã€`blocked_message` ã¨å…±ã« RED ä¿¡å·ã‚’è¿”ã—ã¾ã™ã€‚
        3. æ­£å¸¸ãªå ´åˆï¼ˆé•åãªã—ï¼‰:
           - GREEN ä¿¡å·ã‚’è¿”ã—ã¾ã™ã€‚
        4. ä¾‹å¤–ï¼ˆAPIã‚¨ãƒ©ãƒ¼ç­‰ï¼‰ç™ºç”Ÿæ™‚:
           - `strict_mode` ãŒ True ã®å ´åˆ: å®‰å…¨å´ã«å€’ã—ã€RED ä¿¡å·ã‚’è¿”ã—ã¾ã™ã€‚
           - `strict_mode` ãŒ False ã®å ´åˆ: è­¦å‘Šã‚’ãƒ­ã‚°å‡ºåŠ›ã—ã€ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ãƒ«ãƒ¼ï¼ˆGREENï¼‰ã•ã›ã¾ã™ã€‚

        Args:
            text: ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆã€‚
            entity_name: ãƒ­ã‚°ã‚„ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¡¨ç¤ºã™ã‚‹ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åï¼ˆä¾‹: "User", "Assistant"ï¼‰ã€‚
            blocked_message: ãƒ–ãƒ­ãƒƒã‚¯æ™‚ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¡¨ç¤ºã™ã‚‹å›ºå®šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚
            strict_mode: True ã®å ´åˆã€APIã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ–ãƒ­ãƒƒã‚¯ã—ã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ Falseã€‚

        Returns:
            SemanticGuardResult: åˆ¤å®šçµæœï¼ˆGREEN ã¾ãŸã¯ REDï¼‰ã€‚
        """
        try:
            response = self.openai_client.moderations.create(
                model="omni-moderation-latest", input=text
            )

            guardrail_result = response.results[0]
            if guardrail_result.flagged:
                flagged_categories = [
                    category
                    for category, flagged in guardrail_result.categories.model_dump().items()
                    if flagged
                ]
                return SemanticGuardResult(
                    signal=GuardRailSignal.RED,
                    reason="MODERATION_FLAGGED",
                    detail=f"{entity_name}: {blocked_message} (ã‚«ãƒ†ã‚´ãƒª: {', '.join(flagged_categories)})",
                )

            return SemanticGuardResult(signal=GuardRailSignal.GREEN)
        except Exception as e:
            logger.warning(f"OpenAI Moderation API error: {e}")
            if strict_mode:
                return SemanticGuardResult(
                    signal=GuardRailSignal.RED,
                    reason="MODERATION_ERROR",
                    detail=f"{entity_name}: ç¾åœ¨ã€å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                )
            return SemanticGuardResult(signal=GuardRailSignal.GREEN)

    def check_input_moderation(
        self, input_text: str, entity_name: str, strict_mode: bool = False
    ) -> SemanticGuardResult:
        """
        å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯ã€‚
        ãƒ†ã‚­ã‚¹ãƒˆã‚’ OpenAI Moderation API (`omni-moderation-latest`) ã«é€ä¿¡ã—ã¾ã™ã€‚

        Args:
            input_text: ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            entity_name: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å
            strict_mode: å³æ ¼ãƒ¢ãƒ¼ãƒ‰ã‹ã©ã†ã‹

        Returns:
            SemanticGuardResult
        """
        return self._check_moderation(
            input_text,
            entity_name,
            "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€ãã®å†…å®¹ã¯é©åˆ‡ã§ã¯ãªã„ãŸã‚ã€ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚",
            strict_mode,
        )

    def check_output_moderation(
        self, output_text: str, entity_name: str
    ) -> SemanticGuardResult:
        """
        å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯ã€‚
        ãƒ†ã‚­ã‚¹ãƒˆã‚’ OpenAI Moderation API (`omni-moderation-latest`) ã«é€ä¿¡ã—ã¾ã™ã€‚

        Args:
            output_text: ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            entity_name: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å

        Returns:
            SemanticGuardResult
        """
        return self._check_moderation(
            output_text,
            entity_name,
            "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€é©åˆ‡ãªå›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®è³ªå•ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚",
        )

    @staticmethod
    def _convert_semantic_result_to_dict(
        result: SemanticGuardResult,
    ) -> dict[str, bool | str]:
        """
        SemanticGuardResultã‚’OpenAI Agents SDKãŒæœŸå¾…ã™ã‚‹å½¢å¼ã«å¤‰æ›

        Args:
            result: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚¬ãƒ¼ãƒ‰çµæœ

        Returns:
            å¤‰æ›ã•ã‚ŒãŸè¾æ›¸
        """
        blocked = result.signal == GuardRailSignal.RED
        return {"blocked": blocked, "message": result.detail or ""}

    def create_guardrail(self, entity_name: str, strict_mode: bool = False) -> Callable:
        """
        OpenAI Moderation APIã‚’ä½¿ç”¨ã—ãŸå…¥åŠ›ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«é–¢æ•°ã‚’ä½œæˆ
        BaseGuardRailService ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®Ÿè£…

        Args:
            entity_name: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å
            strict_mode: å³æ ¼ãƒ¢ãƒ¼ãƒ‰ã‹ã©ã†ã‹

        Returns:
            ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«é–¢æ•° (context, agent, input_text) -> dict[str, bool | str]
        """

        def moderation_check(_, __, input_text: str) -> dict[str, bool | str]:
            result = self.check_input_moderation(input_text, entity_name, strict_mode)
            return self._convert_semantic_result_to_dict(result)

        return moderation_check

    def create_output_moderation_guardrail(self, entity_name: str) -> Callable:
        """
        å‡ºåŠ›ç”¨ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«é–¢æ•°ã‚’ä½œæˆ

        Args:
            entity_name: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å

        Returns:
            å‡ºåŠ›ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«é–¢æ•° (context, agent, output_text) -> dict[str, bool | str]
            OpenAI Agents SDKã§ä½¿ç”¨ã•ã‚Œã‚‹å‡ºåŠ›ãƒã‚§ãƒƒã‚¯ç”¨ã®é–¢æ•°
        """

        def output_moderation_check(_, __, output_text: str) -> dict[str, bool | str]:
            result = self.check_output_moderation(output_text, entity_name)
            return self._convert_semantic_result_to_dict(result)

        return output_moderation_check


class SemanticGuardService(BaseGuardRailService):
    """
    ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆChromaDBï¼‰ã‚’æ´»ç”¨ã—ãŸã€æ„å‘³ãƒ™ãƒ¼ã‚¹ã®ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã‚µãƒ¼ãƒ“ã‚¹ã€‚
    ç”Ÿæˆç³»LLMã‚’é€šã•ãšã«ã€ãƒ†ã‚­ã‚¹ãƒˆã®æ„å‘³çš„ãªé¡ä¼¼åº¦ï¼ˆEmbeddingï¼‰ã«åŸºã¥ã„ã¦ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ã®æ¤œçŸ¥ã‚„ãƒŠãƒ¬ãƒƒã‚¸ã®é©åˆæ€§ã‚’åˆ¤å®šã—ã¾ã™ã€‚

    æœ¬ã‚µãƒ¼ãƒ“ã‚¹ã®æœ¬è³ªçš„ãªä»•çµ„ã¿:
    - ã€Œç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ã€ã‚’ã‚ã‚‰ã‹ã˜ã‚ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ä¸Šã«é…ç½®ã—ã¦ãŠãã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆãŒãã‚Œã‚‰ã®ãƒ™ã‚¯ãƒˆãƒ«ã¨ã€Œè¿‘ããªã„ï¼ˆè·é›¢ãŒé›¢ã‚Œã¦ã„ã‚‹ï¼‰ã€ã“ã¨ã‚’ã‚‚ã£ã¦ã€å®‰å…¨ï¼ˆã‚°ãƒªãƒ¼ãƒ³ï¼‰ã§ã‚ã‚‹ã¨åˆ¤å®šã—ã¾ã™ã€‚
    - å˜ãªã‚‹æ–‡å­—åˆ—ã®ä¸€è‡´ã§ã¯ãªãã€æ„å‘³ã®è¿‘æ¥æ€§ã‚’æ•°å€¤åŒ–ï¼ˆDistanceï¼‰ã—ã¦è©•ä¾¡ã™ã‚‹ãŸã‚ã€è¨€ã„æ›ãˆã‚„é¡ä¼¼è¡¨ç¾ã‚‚æ¤œçŸ¥å¯èƒ½ã§ã™ã€‚

    ä¸»ãªç‰¹å¾´ã¨ãƒ¡ãƒªãƒƒãƒˆ:
    - è¶…é«˜é€Ÿãƒ»ä½é…å»¶: åˆ¤å®šã«ç”Ÿæˆç³»LLMï¼ˆæ¨è«–ï¼‰ã‚’ä½¿ç”¨ã›ãšã€Embeddingã¨ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ã¿ã§å®Œçµã™ã‚‹ãŸã‚ã€LLMã¸ã®APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã«æ¯”ã¹ã¦åœ§å€’çš„ã«é«˜é€Ÿã«å‹•ä½œã—ã¾ã™ã€‚
    - ä½ã‚³ã‚¹ãƒˆ: ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»ã®æ¿€ã—ã„ç”Ÿæˆç³»LLMã®å‘¼ã³å‡ºã—å›æ•°ã‚’å‰Šæ¸›ã—ã¦ã€ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚³ã‚¹ãƒˆã‚’ä¸‹ã’ã‚‰ã‚Œã¾ã™

    ä¸»ãªæ©Ÿèƒ½:
    1. ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰æ¤œçŸ¥: ç™»éŒ²ã•ã‚ŒãŸç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã¨å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®æ„å‘³çš„ãªè¿‘ã•ã‚’åˆ¤å®šã€‚é–¾å€¤ã‚ˆã‚Šé ã‘ã‚Œã°å®‰å…¨ã¨ã¿ãªã—ã¾ã™ã€‚
    2. RAGé©åˆæ€§åˆ¤å®š: ç‰¹å®šã®ãƒŠãƒ¬ãƒƒã‚¸ï¼ˆRAGã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼‰ã«å›ç­”ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚

    ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¦‚è¦:
    - 2ã¤ã® ChromaDB ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½¿ã„åˆ†ã‘ã¾ã™ã€‚
        - `forbidden_words`: æ„å‘³çš„ã«ä¸é©åˆ‡ãªå˜èªã‚„ãƒˆãƒ”ãƒƒã‚¯ã‚’æ¤œçŸ¥ã€‚
        - `portfolio_rag`: å›ç­”å¯èƒ½ãªçŸ¥è­˜ç¯„å›²ã‚’ç‰¹å®šã€‚
    - ç”Ÿæˆç³»LLMã®ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã¤ã¤ã€ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ä¸Šã§ã®å¹¾ä½•å­¦çš„ãªä½ç½®é–¢ä¿‚ã«åŸºã¥ã„ãŸé«˜åº¦ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
    """

    def __init__(
        self,
        api_key: str | None = None,
        persist_directory: str | None = None,
        forbidden_words_collection_name: str = "forbidden_words",
        rag_collection_name: str = "portfolio_rag",
        embedding_model: str = "text-embedding-3-small",
    ):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY is required for SemanticGuardService")

        self.embedding_model = embedding_model

        persist_path = persist_directory or os.getenv("CHROMA_DB_PATH", "./chroma_db")
        if not os.path.isabs(persist_path):
            persist_path = str(Path(BASE_DIR) / persist_path)

        self._client_db = chromadb.PersistentClient(
            path=persist_path, settings=Settings(allow_reset=True)
        )
        self.openai_ef = OpenAIEmbeddingFunction(
            api_key=self.api_key, model_name=self.embedding_model
        )

        # ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ç”¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        self._forbidden_words_collection = self._client_db.get_or_create_collection(
            name=forbidden_words_collection_name, embedding_function=self.openai_ef
        )

        # ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢ç”¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ—¢å­˜ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‚ç…§ã™ã‚‹ã“ã¨ã‚’æƒ³å®šï¼‰
        self._rag_collection = self._client_db.get_or_create_collection(
            name=rag_collection_name, embedding_function=self.openai_ef
        )

    def setup_forbidden_words(self, words: list[str]):
        """
        ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’ Embedding åŒ–ã—ã¦ ChromaDB ã«ç™»éŒ²ã—ã¾ã™ï¼ˆåˆæœŸåŒ–ãƒ»æ›´æ–°ç”¨ï¼‰ã€‚

        å‡¦ç†ã®æµã‚Œ:
        1. æŒ‡å®šã•ã‚ŒãŸåå‰ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã™ã¹ã¦å‰Šé™¤ã—ã¾ã™ã€‚
        2. æ–°ã—ã„ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€ãã‚Œãã‚Œã«å¯¾ã—ã¦ Embedding ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
        3. ID, Document, Metadata ã‚’ã‚»ãƒƒãƒˆã«ã—ã¦ ChromaDB ã«æ°¸ç¶šåŒ–ã—ã¾ã™ã€‚
        """
        logger.info(f"Setting up {len(words)} forbidden words...")

        # 1. æ—¢å­˜ã®ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¦å‰Šé™¤
        existing_data = self._forbidden_words_collection.get()
        if existing_data["ids"]:
            self._forbidden_words_collection.delete(ids=existing_data["ids"])
            logger.debug(
                f"Cleared {len(existing_data['ids'])} existing forbidden words."
            )

        # 2. æ–°ã—ã„ãƒ¯ãƒ¼ãƒ‰ã‚’ç™»éŒ²
        ids = [f"word_{i}" for i in range(len(words))]
        metadatas = [{"word": word} for word in words]

        self._forbidden_words_collection.upsert(
            ids=ids, documents=words, metadatas=metadatas
        )
        logger.info("Forbidden words setup completed.")

    def check_rag_hit(self, user_input: str) -> bool:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãŒãƒŠãƒ¬ãƒƒã‚¸ï¼ˆRAGï¼‰ã®ç¯„å›²å†…ã«ã‚ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚

        å‡¦ç†ã®è©³ç´°:
        - å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€RAGç”¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«å¯¾ã—ã¦é¡ä¼¼æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
        - ç”Ÿæˆç³»LLMã«ã‚ˆã‚‹æ¨è«–ã‚’è¡Œã‚ãªã„ãŸã‚ã€éå¸¸ã«é«˜é€Ÿã«åˆ¤å®šãŒå¯èƒ½ã§ã™ã€‚
        - 1ä»¶ã§ã‚‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Œã°ã€ŒãƒŠãƒ¬ãƒƒã‚¸ã‚ã‚Šã€ã¨åˆ¤å®šã—ã¾ã™ã€‚
        - æ³¨æ„: ç¾æ™‚ç‚¹ã§ã¯è·é›¢ï¼ˆDistanceï¼‰ã«ã‚ˆã‚‹å³å¯†ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¯è¡Œã‚ãšã€å­˜åœ¨ç¢ºèªã®ã¿ã‚’è¡Œã„ã¾ã™ã€‚
        """
        results = self._rag_collection.query(query_texts=[user_input], n_results=1)
        return bool(results and results.get("documents") and results["documents"][0])

    def check_forbidden_words(self, text: str):
        """
        ãƒ†ã‚­ã‚¹ãƒˆãŒç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ã«ã€Œæ„å‘³çš„ã«ã€åˆè‡´ã™ã‚‹ã‹ã‚’åˆ¤å®šã—ã¾ã™ã€‚

        åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆè¿‘æ¥æ€§ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰:
        1. ã‚ã‚‰ã‹ã˜ã‚ç”¨æ„ã•ã‚ŒãŸã€Œç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ã€ã®ãƒ™ã‚¯ãƒˆãƒ«ç¾¤ã®ä¸­ã‹ã‚‰ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã«æœ€ã‚‚è¿‘ã„ã‚‚ã®ã‚’æ¤œç´¢ã—ã¾ã™ã€‚
           - ã“ã®æ¤œç´¢ã¯ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆã¾ãŸã¯ãƒ™ã‚¯ãƒˆãƒ«DBï¼‰ã§ã®ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ã®ã¿ã§è¡Œã‚ã‚Œã‚‹ãŸã‚ã€ç”Ÿæˆç³»LLMã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒç™ºç”Ÿã›ãšã€æ¥µã‚ã¦ä½é…å»¶ã§ã™ã€‚
        2. æ¤œç´¢çµæœã¨ã®è·é›¢ï¼ˆDistanceï¼‰ã‚’æ¸¬å®šã—ã¾ã™ã€‚
        3. åˆ¤å®šã®æ ¹æ‹ :
           - è·é›¢ãŒ `threshold` (0.35) ä»¥ä¸Šã§ã‚ã‚Œã°ã€ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ã¨ã€Œè¿‘ããªã„ã€ãŸã‚ã€å®‰å…¨ï¼ˆã‚°ãƒªãƒ¼ãƒ³ï¼‰ã¨ã¿ãªã—ã¾ã™ã€‚
           - è·é›¢ãŒ `threshold` (0.35) æœªæº€ã®å ´åˆã€æ„å‘³çš„ã«æ¥µã‚ã¦è¿‘ã„ã¨åˆ¤æ–­ã—ã€ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆãƒ¬ãƒƒãƒ‰ï¼‰ã—ã¾ã™ã€‚

        ä¾‹å¤–:
            SemanticGuardException: ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ã¨ã®è·é›¢ãŒè¿‘ãã€ãƒªã‚¹ã‚¯ãŒã‚ã‚‹ã¨åˆ¤å®šã•ã‚ŒãŸå ´åˆã«ç™ºç”Ÿã—ã¾ã™ã€‚
        """
        # è·é›¢(distance)ã®é–¾å€¤ã‚’è¨­å®šã€‚æ„å‘³çš„ã«è¿‘ã„ã‚‚ã®ã‚’æ¤œçŸ¥ã™ã‚‹ãŸã‚
        # OpenAI embedding ã®å ´åˆã€0.2~0.4 ç¨‹åº¦ãŒã€Œã‹ãªã‚Šè¿‘ã„ã€
        threshold = 0.35

        results = self._forbidden_words_collection.query(
            query_texts=[text], n_results=1
        )

        if results and results.get("distances") and results["distances"][0]:
            distance = results["distances"][0][0]
            word = results["documents"][0][0]

            logger.debug(f"Forbidden word search: distance={distance}, word={word}")

            if distance < threshold:
                logger.warning(
                    f"ğŸ”´ RED: Forbidden word detected: {word} (distance: {distance})"
                )
                raise SemanticGuardException(
                    SemanticGuardResult(
                        signal=GuardRailSignal.RED,
                        reason="FORBIDDEN_WORD_DETECTED",
                        detail=f"ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ã€Œ{word}ã€ã«æ„å‘³çš„ã«ãƒ’ãƒƒãƒˆã—ã¾ã—ãŸã€‚",
                    )
                )

    def evaluate(
        self, user_input: str, llm_response_provider=None
    ) -> SemanticGuardResult:
        """
        æ„å‘³å·®åˆ†æ¤œç´¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã€å…¥åŠ›ã®å®‰å…¨æ€§ã‚’è©•ä¾¡ã—ã¾ã™ã€‚

        ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚¹ãƒ†ãƒƒãƒ—:
        1. RAGç¢ºèª: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãŒãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã«å­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚
           - ãƒ’ãƒƒãƒˆã—ãŸå ´åˆ: GREEN åˆ¤å®šã§çµ‚äº†ï¼ˆä¿¡é ¼ã§ãã‚‹å›ç­”ãŒå¯èƒ½ãªãŸã‚ï¼‰ã€‚
        2. RAGãƒŸã‚¹æ™‚: YELLOW åˆ¤å®šã¸ç§»è¡Œã—ã€å¤–éƒ¨ï¼ˆä¸€èˆ¬LLMï¼‰ã¸ã®å•ã„åˆã‚ã›ã‚’æº–å‚™ã—ã¾ã™ã€‚
        3. ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ: `llm_response_provider` ã‚’é€šã˜ã¦ä¸€èˆ¬LLMã‹ã‚‰å›ç­”ã‚’å–å¾—ã—ã¾ã™ã€‚
        4. å‡ºåŠ›æ¤œæŸ»: ä¸€èˆ¬LLMãŒç”Ÿæˆã—ãŸå›ç­”ã«å¯¾ã—ã¦ã€`check_forbidden_words` ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
           - ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹å ´åˆ: RED åˆ¤å®šï¼ˆä¾‹å¤–ç™ºç”Ÿï¼‰ã€‚
           - å«ã¾ã‚Œãªã„å ´åˆ: YELLOW åˆ¤å®šã§å›ç­”ã‚’è¨±å¯ã—ã¾ã™ã€‚

        Args:
            user_input: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã€‚
            llm_response_provider: (text) -> str ã®å½¢å¼ã®å‘¼ã³å‡ºã—å¯èƒ½ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚RAGãƒŸã‚¹æ™‚ã®å›ç­”ç”Ÿæˆã«ä½¿ç”¨ã€‚

        Returns:
            SemanticGuardResult: æœ€çµ‚çš„ãªåˆ¤å®šçµæœï¼ˆGREEN ã¾ãŸã¯ YELLOWï¼‰ã€‚
        """
        logger.info(f"Evaluating user input: {user_input[:50]}...")

        # 1. RAGãƒ’ãƒƒãƒˆç¢ºèª
        if self.check_rag_hit(user_input):
            logger.info("ğŸŸ¢ GREEN: RAG hit.")
            return SemanticGuardResult(
                signal=GuardRailSignal.GREEN,
                reason="RAG_HIT",
                detail="ç¤¾å†…ãƒŠãƒ¬ãƒƒã‚¸ã«åŸºã¥ãå›ç­”ãŒå¯èƒ½ã§ã™ã€‚",
            )

        # 2. RAGãƒ’ãƒƒãƒˆãªã—
        logger.info("ğŸŸ¡ YELLOW: RAG miss. Proceeding to general LLM.")
        if llm_response_provider is None:
            return SemanticGuardResult(
                signal=GuardRailSignal.YELLOW,
                reason="RAG_MISS",
                detail="RAGãƒ’ãƒƒãƒˆãªã—ã€‚ä¸€èˆ¬LLMå•ã„åˆã‚ã›ãŒå¿…è¦ã§ã™ï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒã‚¤ãƒ€æœªæŒ‡å®šï¼‰ã€‚",
            )

        # 3. ä¸€èˆ¬LLMå•ã„åˆã‚ã›
        llm_response = llm_response_provider(user_input)

        # 4. ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰é™¤å¤–æ¤œæŸ» (REDåˆ¤å®šãªã‚‰Exception)
        self.check_forbidden_words(llm_response)

        return SemanticGuardResult(
            signal=GuardRailSignal.YELLOW,
            reason="RAG_MISS",
            detail="ä¸€èˆ¬LLMå•ã„åˆã‚ã›ãƒ«ãƒ¼ãƒˆï¼ˆç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯é€šéï¼‰",
        )

    def create_guardrail(self, *args, **kwargs) -> Callable:
        """
        OpenAI Agents SDKã§ä½¿ç”¨ã•ã‚Œã‚‹å…¥åŠ›ãƒ»å‡ºåŠ›ãƒã‚§ãƒƒã‚¯ç”¨ã®é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚
        BaseGuardRailService ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®Ÿè£…ã§ã™ã€‚

        ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã®æ€§è³ª:
        - æ„å‘³çš„ãªè·é›¢ã«åŸºã¥ããƒã‚§ãƒƒã‚¯: å…¥åŠ›ãƒ»å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆãŒã€ã‚ã‚‰ã‹ã˜ã‚ç™»éŒ²ã•ã‚ŒãŸç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ã®ãƒ™ã‚¯ãƒˆãƒ«ç¾¤ã‹ã‚‰ã€Œååˆ†ã«é›¢ã‚Œã¦ã„ã‚‹ï¼ˆè¿‘ããªã„ï¼‰ã€ã“ã¨ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
        - è·é›¢ãŒé–¾å€¤ã‚’è¶…ãˆã¦ã„ã‚Œã°ï¼ˆé ã‘ã‚Œã°ï¼‰ãƒ–ãƒ­ãƒƒã‚¯ã›ãšã€é–¾å€¤æœªæº€ï¼ˆè¿‘ã‘ã‚Œã°ï¼‰ãƒ–ãƒ­ãƒƒã‚¯ã—ã¾ã™ã€‚
        """

        def semantic_check(_, __, text: str) -> dict[str, bool | str]:
            try:
                self.check_forbidden_words(text)
                return {"blocked": False}
            except SemanticGuardException as sge:
                return {"blocked": True, "message": sge.result.detail}
            except Exception as e:
                logger.warning(f"Semantic Guard error: {e}")
                return {"blocked": False}

        return semantic_check
