from abc import ABC, abstractmethod
import os
import logging
from pathlib import Path
from typing import Callable

import chromadb
from chromadb.config import Settings
from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction
from openai import OpenAI

from lib.llm.valueobject.guardrail import (
    GuardRailSignal,
    SemanticGuardResult,
    SemanticGuardException,
)
from config.settings import BASE_DIR

logger = logging.getLogger(__name__)


class BaseGuardRailService(ABC):
    """
    ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã‚µãƒ¼ãƒ“ã‚¹ã®åŸºåº•ã‚¯ãƒ©ã‚¹
    """

    @abstractmethod
    def create_guardrail(self, *args, **kwargs) -> Callable:
        """
        OpenAI Agents SDKã§ä½¿ç”¨ã•ã‚Œã‚‹ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«é–¢æ•°ã‚’ä½œæˆã™ã‚‹
        """
        pass


class OpenAIModerationService(BaseGuardRailService):
    """
    Moderationæ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹
    OpenAI Moderation APIã‚’ä½¿ç”¨ã—ãŸå…¥åŠ›ãƒ»å‡ºåŠ›ã®ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
    """

    def __init__(self):
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    def _check_moderation(
        self,
        text: str,
        entity_name: str,
        blocked_message: str,
        strict_mode: bool = False,
    ) -> SemanticGuardResult:
        """
        OpenAI Moderation APIã‚’ä½¿ç”¨ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯

        Args:
            text: ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
            entity_name: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å
            blocked_message: ãƒ–ãƒ­ãƒƒã‚¯æ™‚ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            strict_mode: å³æ ¼ãƒ¢ãƒ¼ãƒ‰ã‹ã©ã†ã‹

        Returns:
            SemanticGuardResult
        """
        try:
            response = self.openai_client.moderations.create(
                model="omni-moderation-latest", input=text
            )

            moderation_result = response.results[0]
            if moderation_result.flagged:
                flagged_categories = [
                    category
                    for category, flagged in moderation_result.categories.model_dump().items()
                    if flagged
                ]
                return SemanticGuardResult(
                    signal=GuardRailSignal.RED,
                    reason="MODERATION_FLAGGED",
                    detail=f"{entity_name}: {blocked_message} (ã‚«ãƒ†ã‚´ãƒª: {', '.join(flagged_categories)})",
                )

            return SemanticGuardResult(signal=GuardRailSignal.GREEN)
        except Exception as e:
            logger.warning(f"OpenAI Moderation API error: {e}")
            if strict_mode:
                return SemanticGuardResult(
                    signal=GuardRailSignal.RED,
                    reason="MODERATION_ERROR",
                    detail=f"{entity_name}: ç¾åœ¨ã€å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã—ã°ã‚‰ãã—ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                )
            return SemanticGuardResult(signal=GuardRailSignal.GREEN)

    def check_input_moderation(
        self, input_text: str, entity_name: str, strict_mode: bool = False
    ) -> SemanticGuardResult:
        """
        å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯

        Args:
            input_text: ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            entity_name: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å
            strict_mode: å³æ ¼ãƒ¢ãƒ¼ãƒ‰ã‹ã©ã†ã‹

        Returns:
            SemanticGuardResult
        """
        return self._check_moderation(
            input_text,
            entity_name,
            "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€ãã®å†…å®¹ã¯é©åˆ‡ã§ã¯ãªã„ãŸã‚ã€ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚",
            strict_mode,
        )

    def check_output_moderation(
        self, output_text: str, entity_name: str
    ) -> SemanticGuardResult:
        """
        å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯

        Args:
            output_text: ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            entity_name: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å

        Returns:
            SemanticGuardResult
        """
        return self._check_moderation(
            output_text,
            entity_name,
            "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€é©åˆ‡ãªå›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®è³ªå•ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚",
        )

    @staticmethod
    def _convert_semantic_result_to_dict(
        result: SemanticGuardResult,
    ) -> dict[str, bool | str]:
        """
        SemanticGuardResultã‚’OpenAI Agents SDKãŒæœŸå¾…ã™ã‚‹å½¢å¼ã«å¤‰æ›

        Args:
            result: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚¬ãƒ¼ãƒ‰çµæœ

        Returns:
            å¤‰æ›ã•ã‚ŒãŸè¾æ›¸
        """
        blocked = result.signal == GuardRailSignal.RED
        return {"blocked": blocked, "message": result.detail or ""}

    def create_guardrail(self, entity_name: str, strict_mode: bool = False) -> Callable:
        """
        OpenAI Moderation APIã‚’ä½¿ç”¨ã—ãŸå…¥åŠ›ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«é–¢æ•°ã‚’ä½œæˆ
        BaseGuardRailService ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®Ÿè£…

        Args:
            entity_name: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å
            strict_mode: å³æ ¼ãƒ¢ãƒ¼ãƒ‰ã‹ã©ã†ã‹

        Returns:
            ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«é–¢æ•° (context, agent, input_text) -> dict[str, bool | str]
        """

        def moderation_check(_, __, input_text: str) -> dict[str, bool | str]:
            result = self.check_input_moderation(input_text, entity_name, strict_mode)
            return self._convert_semantic_result_to_dict(result)

        return moderation_check

    def create_output_moderation_guardrail(self, entity_name: str) -> Callable:
        """
        å‡ºåŠ›ç”¨ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«é–¢æ•°ã‚’ä½œæˆ

        Args:
            entity_name: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å

        Returns:
            å‡ºåŠ›ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«é–¢æ•° (context, agent, output_text) -> dict[str, bool | str]
            OpenAI Agents SDKã§ä½¿ç”¨ã•ã‚Œã‚‹å‡ºåŠ›ãƒã‚§ãƒƒã‚¯ç”¨ã®é–¢æ•°
        """

        def output_moderation_check(_, __, output_text: str) -> dict[str, bool | str]:
            result = self.check_output_moderation(output_text, entity_name)
            return self._convert_semantic_result_to_dict(result)

        return output_moderation_check


class SemanticGuardService(BaseGuardRailService):
    """
    Chroma ã‚’ç”¨ã„ãŸæ„å‘³å·®åˆ†æ¤œç´¢ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«
    ç”Ÿæˆç³»LLMã‚’å‘¼ã°ãšã€embedding + ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ã¿ã§ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ç­‰ã‚’æ¤œçŸ¥ã™ã‚‹
    """

    def __init__(
        self,
        api_key: str | None = None,
        persist_directory: str | None = None,
        forbidden_words_collection_name: str = "forbidden_words",
        rag_collection_name: str = "portfolio_rag",
        embedding_model: str = "text-embedding-3-small",
    ):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY is required for SemanticGuardService")

        self.embedding_model = embedding_model

        persist_path = persist_directory or os.getenv("CHROMA_DB_PATH", "./chroma_db")
        if not os.path.isabs(persist_path):
            persist_path = str(Path(BASE_DIR) / persist_path)

        self._client_db = chromadb.PersistentClient(
            path=persist_path, settings=Settings(allow_reset=True)
        )
        self.openai_ef = OpenAIEmbeddingFunction(
            api_key=self.api_key, model_name=self.embedding_model
        )

        # ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ç”¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
        self._forbidden_words_collection = self._client_db.get_or_create_collection(
            name=forbidden_words_collection_name, embedding_function=self.openai_ef
        )

        # ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢ç”¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ—¢å­˜ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‚ç…§ã™ã‚‹ã“ã¨ã‚’æƒ³å®šï¼‰
        self._rag_collection = self._client_db.get_or_create_collection(
            name=rag_collection_name, embedding_function=self.openai_ef
        )

    def setup_forbidden_words(self, words: list[str]):
        """
        ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’ embedding åŒ–ã—ã¦ Chroma ã«æ°¸ç¶šåŒ–ã™ã‚‹ï¼ˆåˆæœŸåŒ–ãƒ•ã‚§ãƒ¼ã‚ºç”¨ï¼‰
        æ—¢å­˜ã®ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ã¯ã™ã¹ã¦å‰Šé™¤ã•ã‚Œã€æ–°ã—ã„ãƒªã‚¹ãƒˆã§ä¸Šæ›¸ãã•ã‚Œã¾ã™ã€‚
        """
        logger.info(f"Setting up {len(words)} forbidden words...")

        # 1. æ—¢å­˜ã®ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¦å‰Šé™¤
        existing_data = self._forbidden_words_collection.get()
        if existing_data["ids"]:
            self._forbidden_words_collection.delete(ids=existing_data["ids"])
            logger.debug(
                f"Cleared {len(existing_data['ids'])} existing forbidden words."
            )

        # 2. æ–°ã—ã„ãƒ¯ãƒ¼ãƒ‰ã‚’ç™»éŒ²
        ids = [f"word_{i}" for i in range(len(words))]
        metadatas = [{"word": word} for word in words]

        self._forbidden_words_collection.upsert(
            ids=ids, documents=words, metadatas=metadatas
        )
        logger.info("Forbidden words setup completed.")

    def check_rag_hit(self, user_input: str) -> bool:
        """
        RAGã«ãƒ’ãƒƒãƒˆã™ã‚‹ã‹ç¢ºèªã™ã‚‹
        documents ãŒç©ºã§ãªã‘ã‚Œã°ãƒ’ãƒƒãƒˆã¨ã¿ãªã™ï¼ˆè·é›¢ã®é–¾å€¤ã¯è¦æ¤œè¨ã ãŒã€ã¾ãšã¯å­˜åœ¨ç¢ºèªï¼‰
        """
        results = self._rag_collection.query(query_texts=[user_input], n_results=1)
        return bool(results and results.get("documents") and results["documents"][0])

    def check_forbidden_words(self, text: str):
        """
        ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ã«æ„å‘³çš„ã«ãƒ’ãƒƒãƒˆã™ã‚‹ã‹ç¢ºèªã™ã‚‹
        ãƒ’ãƒƒãƒˆã—ãŸå ´åˆã¯ SemanticGuardException ã‚’æŠ•ã’ã‚‹

        â€»ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ embedding API ã‚’å‘¼ã³å‡ºã—ã¾ã™ãŒã€ç”Ÿæˆç³»LLMã¯å‘¼ã³å‡ºã—ã¾ã›ã‚“ã€‚
        """
        # è·é›¢(distance)ã®é–¾å€¤ã‚’è¨­å®šã€‚æ„å‘³çš„ã«è¿‘ã„ã‚‚ã®ã‚’æ¤œçŸ¥ã™ã‚‹ãŸã‚
        # OpenAI embedding ã®å ´åˆã€0.2~0.4 ç¨‹åº¦ãŒã€Œã‹ãªã‚Šè¿‘ã„ã€
        threshold = 0.35

        results = self._forbidden_words_collection.query(
            query_texts=[text], n_results=1
        )

        if results and results.get("distances") and results["distances"][0]:
            distance = results["distances"][0][0]
            word = results["documents"][0][0]

            logger.debug(f"Forbidden word search: distance={distance}, word={word}")

            if distance < threshold:
                logger.warning(
                    f"ğŸ”´ RED: Forbidden word detected: {word} (distance: {distance})"
                )
                raise SemanticGuardException(
                    SemanticGuardResult(
                        signal=GuardRailSignal.RED,
                        reason="FORBIDDEN_WORD_DETECTED",
                        detail=f"ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ã€Œ{word}ã€ã«æ„å‘³çš„ã«ãƒ’ãƒƒãƒˆã—ã¾ã—ãŸã€‚",
                    )
                )

    def evaluate(
        self, user_input: str, llm_response_provider=None
    ) -> SemanticGuardResult:
        """
        æ„å‘³å·®åˆ†æ¤œç´¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹

        1. ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢ï¼ˆRAGãƒ’ãƒƒãƒˆç¢ºèªï¼‰
        2. RAGãƒ’ãƒƒãƒˆã‚ã‚Š -> GREEN
        3. RAGãƒ’ãƒƒãƒˆãªã— -> YELLOW -> ä¸€èˆ¬LLMå•ã„åˆã‚ã›
        4. ä¸€èˆ¬LLMå‡ºåŠ›ã®ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰é™¤å¤–æ¤œæŸ»
        5. ãƒ’ãƒƒãƒˆã™ã‚Œã° RED (Exception)
        """
        logger.info(f"Evaluating user input: {user_input[:50]}...")

        # 1. RAGãƒ’ãƒƒãƒˆç¢ºèª
        if self.check_rag_hit(user_input):
            logger.info("ğŸŸ¢ GREEN: RAG hit.")
            return SemanticGuardResult(
                signal=GuardRailSignal.GREEN,
                reason="RAG_HIT",
                detail="ç¤¾å†…ãƒŠãƒ¬ãƒƒã‚¸ã«åŸºã¥ãå›ç­”ãŒå¯èƒ½ã§ã™ã€‚",
            )

        # 2. RAGãƒ’ãƒƒãƒˆãªã—
        logger.info("ğŸŸ¡ YELLOW: RAG miss. Proceeding to general LLM.")
        if llm_response_provider is None:
            return SemanticGuardResult(
                signal=GuardRailSignal.YELLOW,
                reason="RAG_MISS",
                detail="RAGãƒ’ãƒƒãƒˆãªã—ã€‚ä¸€èˆ¬LLMå•ã„åˆã‚ã›ãŒå¿…è¦ã§ã™ï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒã‚¤ãƒ€æœªæŒ‡å®šï¼‰ã€‚",
            )

        # 3. ä¸€èˆ¬LLMå•ã„åˆã‚ã›
        llm_response = llm_response_provider(user_input)

        # 4. ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰é™¤å¤–æ¤œæŸ» (REDåˆ¤å®šãªã‚‰Exception)
        self.check_forbidden_words(llm_response)

        return SemanticGuardResult(
            signal=GuardRailSignal.YELLOW,
            reason="RAG_MISS",
            detail="ä¸€èˆ¬LLMå•ã„åˆã‚ã›ãƒ«ãƒ¼ãƒˆï¼ˆç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯é€šéï¼‰",
        )

    def create_guardrail(self, *args, **kwargs) -> Callable:
        """
        OpenAI Agents SDKã§ä½¿ç”¨ã•ã‚Œã‚‹å…¥åŠ›ãƒ»å‡ºåŠ›ãƒã‚§ãƒƒã‚¯ç”¨ã®é–¢æ•°ã‚’ä½œæˆ
        BaseGuardRailService ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®Ÿè£…
        """

        def semantic_check(_, __, text: str) -> dict[str, bool | str]:
            try:
                self.check_forbidden_words(text)
                return {"blocked": False}
            except SemanticGuardException as sge:
                return {"blocked": True, "message": sge.result.detail}
            except Exception as e:
                logger.warning(f"Semantic Guard error: {e}")
                return {"blocked": False}

        return semantic_check
